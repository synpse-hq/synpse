templates:
- id: ollama
  name: Ollama
  imageUrl: 'https://ollama.com/public/ollama.png'
  description: 'Run Llama 2, Code Llama, and other models on CPU or GPU machines.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/ollama.yaml
  gpu: optional
  parameters:
  - name: Port
    description: "Port to expose Ollama API on"
    type: int
    default: "11434"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/ollama"
- id: vllm-mistral-7b
  name: Mistral 7B (vLLM)
  imageUrl: 'https://mistral.ai/images/logo_hubc88c4ece131b91c7cb753f40e9e1cc5_2589_256x0_resize_q97_h2_lanczos_3.webp'
  description: 'Run Mistral 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "mistralai/Mistral-7B-v0.1"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
- id: vllm-gemma-7b
  name: Google Gemma 7B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "google/gemma-2b"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
- id: vllm-gemma-2b
  name: Google Gemma 2B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 2B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "google/gemma-2b"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
  