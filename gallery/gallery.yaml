templates:
- id: ollama
  name: Ollama
  # imageUrl: 'https://avatars.githubusercontent.com/u/151674099?s=200&v=4'
  imageUrl: 'https://storage.googleapis.com/downloads.synpse.net/gallery-assets/ollama.png'
  description: 'Run Llama 2, Code Llama, and other models on CPU or GPU machines.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/ollama.yaml
  gpu: optional
  parameters:
  - name: Port
    description: "Port to expose Ollama API on"
    type: int
    default: "11434"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/ollama"
- id: vllm-mistral-7b
  name: Mistral 7B (vLLM)
  imageUrl: 'https://avatars.githubusercontent.com/u/132372032?s=200&v=4'
  description: 'Run Mistral 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "mistralai/Mistral-7B-v0.1"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
#
# Google Gemma models
#
- id: vllm-gemma-7b
  name: Google Gemma 7B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "google/gemma-2b"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
- id: vllm-gemma-2b
  name: Google Gemma 2B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 2B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "google/gemma-2b"
    readonly: true
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
# 
# Replicate Cogs
#
- id: incredibly-fast-whisper
  name: Incredibly Fast Whisper
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/4c5d637c-c441-4857-9791-7c11111b38b4/52ebbd85-50a7-4741-b398-30e31.webp'
  description: 'whisper-large-v3, incredibly fast, powered by Hugging Face Transformers!'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: CogImage
    description: "Model - https://replicate.com/vaibhavs10/incredibly-fast-whisper?input=docker"
    type: text
    default: "r8.im/vaibhavs10/incredibly-fast-whisper@sha256:3ab86df6c8f54c11309d4d1f930ac292bad43ace52d10c80d87eb258b3c9f79c"
    readonly: true

- id: sdxl
  name: Stable Diffusion XL
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/9065f9e3-40da-4742-8cb8-adfa8e794c0d/sdxl_cover.jpg'
  description: 'A text-to-image generative AI model that creates beautiful images'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: CogImage
    description: "Model - https://replicate.com/stability-ai/sdxl?input=docker"
    type: text
    default: "r8.im/stability-ai/sdxl@sha256:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b"
    readonly: true

- id: llava-13b
  name: Stable Diffusion XL
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/454548d6-4978-4d85-bca3-d067dfc031bf/llava.png'
  description: 'Visual instruction tuning towards large language and vision models with GPT-4 level capabilities'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: CogImage
    description: "Model - https://replicate.com/yorickvp/llava-13b?input=docker"
    type: text
    default: "r8.im/yorickvp/llava-13b@sha256:01359160a4cff57c6b7d4dc625d0019d390c7c46f553714069f114b392f4a726"
    readonly: true