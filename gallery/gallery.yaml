templates:
- id: ollama
  name: Ollama
  # imageUrl: 'https://avatars.githubusercontent.com/u/151674099?s=200&v=4'
  imageUrl: 'https://storage.googleapis.com/downloads.synpse.net/gallery-assets/ollama.png'
  description: 'Run Llama 2, Code Llama, and other models on CPU or GPU machines.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/ollama.yaml
  gpu: optional
  parameters:
  - name: Port
    description: "Port to expose Ollama API on"
    type: int
    default: "11434"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/ollama"
- id: vllm-mistral-7b
  name: Mistral 7B (vLLM)
  imageUrl: 'https://avatars.githubusercontent.com/u/132372032?s=200&v=4'
  description: 'Run Mistral 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "mistralai/Mistral-7B-v0.1"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
#
# Google Gemma models
#
- id: vllm-gemma-7b
  name: Google Gemma 7B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "google/gemma-2b"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
- id: vllm-gemma-2b
  name: Google Gemma 2B (vLLM)
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 2B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "google/gemma-2b"
    readonly: true
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
# 
# Replicate Cogs
#
- id: incredibly-fast-whisper
  name: Incredibly Fast Whisper
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/4c5d637c-c441-4857-9791-7c11111b38b4/52ebbd85-50a7-4741-b398-30e31.webp'
  description: 'whisper-large-v3, incredibly fast, powered by Hugging Face Transformers!'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required