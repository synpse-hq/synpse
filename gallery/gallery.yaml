templates:
- id: ollama
  organization: Ollama
  name: Ollama
  categories:
  - AI
  - Text
  # imageUrl: 'https://avatars.githubusercontent.com/u/151674099?s=200&v=4'
  imageUrl: 'https://storage.googleapis.com/downloads.synpse.net/gallery-assets/ollama.png'
  description: 'Run Llama 2, Code Llama, and other models on CPU or GPU machines.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/ollama.yaml
  gpu: optional
  parameters:
  - name: Port
    description: "Port to expose Ollama API on"
    type: int
    default: "11434"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/ollama"
- id: vllm-mistral-7b
  organization: Mistral AI
  name: Mistral 7B (vLLM)
  categories:
  - AI
  - Text
  imageUrl: 'https://avatars.githubusercontent.com/u/132372032?s=200&v=4'
  description: 'Run Mistral 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "mistralai/Mistral-7B-v0.1"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
#
# Google Gemma models
#
- id: vllm-gemma-7b
  organization: Google
  name: Gemma 7B (vLLM)
  categories:
  - AI
  - Text
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 7B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    readonly: true
    default: "google/gemma-2b"
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
- id: vllm-gemma-2b
  organization: Google
  name: Gemma 2B (vLLM)
  categories:
  - AI
  - Text
  imageUrl: 'https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp'
  description: 'Run Google Gemma 2B model on a GPU machine. Exposes OpenAI compatible API.'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/vllm.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "8000"
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/vllm"
  - name: Model
    description: "Model name (supported models: https://docs.vllm.ai/en/latest/models/supported_models.html)"
    type: text
    default: "google/gemma-2b"
    readonly: true
  - name: HuggingFaceToken
    description: "Hugging Face API token, get yours here https://huggingface.co/docs/hub/en/security-tokens"
    type: text
    default: ""
# 
# Replicate Cogs
#
- id: incredibly-fast-whisper
  organization: vaibhavs10
  name: Incredibly Fast Whisper
  categories:
  - AI
  - Audio
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/4c5d637c-c441-4857-9791-7c11111b38b4/52ebbd85-50a7-4741-b398-30e31.webp'
  description: 'whisper-large-v3, incredibly fast, powered by Hugging Face Transformers!'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "5000"
  - name: CogImage
    description: "Model - https://replicate.com/vaibhavs10/incredibly-fast-whisper?input=docker"
    type: text
    default: "r8.im/vaibhavs10/incredibly-fast-whisper@sha256:3ab86df6c8f54c11309d4d1f930ac292bad43ace52d10c80d87eb258b3c9f79c"
    readonly: true

- id: sdxl
  organization: Stability AI
  name: Stable Diffusion XL
  categories:
  - AI
  - Images
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/9065f9e3-40da-4742-8cb8-adfa8e794c0d/sdxl_cover.jpg'
  description: 'A text-to-image generative AI model that creates beautiful images'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "5000"
  - name: CogImage
    description: "Model - https://replicate.com/stability-ai/sdxl?input=docker"
    type: text
    default: "r8.im/stability-ai/sdxl@sha256:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b"
    readonly: true

- id: clarity-upscaler
  organization: philz1337x
  name: Clarity Upscaler
  categories:
  - AI
  - Images
  imageUrl: 'https://tjzk.replicate.delivery/models_models_cover_image/bc4eb965-f228-456f-96e2-430af00ca582/Bildschirmfoto_2024-03-20_um_07.2.png'
  description: 'High resolution image Upscaler and Enhancer'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "5000"
  - name: CogImage
    description: "Model - https://replicate.com/philz1337x/clarity-upscaler?input=docker"
    type: text
    default: "r8.im/philz1337x/clarity-upscaler@sha256:abd484acb51ad450b06f42f76940fa5c1b37511dbf70ac8594fdacd5c3302307"
    readonly: true

- id: llava-13b
  organization: yorickvp
  name: LLAVA 13B
  categories:
  - AI
  - Images
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/454548d6-4978-4d85-bca3-d067dfc031bf/llava.png'
  description: 'Visual instruction tuning towards large language and vision models with GPT-4 level capabilities'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "5000"
  - name: CogImage
    description: "Model - https://replicate.com/yorickvp/llava-13b?input=docker"
    type: text
    default: "r8.im/yorickvp/llava-13b@sha256:01359160a4cff57c6b7d4dc625d0019d390c7c46f553714069f114b392f4a726"
    readonly: true

- id: google-research/maxim
  organization: Google
  name: Multi-Axis MLP for Image Processing
  categories:
  - AI
  imageUrl: 'https://tjzk.replicate.delivery/models_models_featured_image/df5769aa-0908-4a2e-9378-c582838461db/1fromGOPR0950.png'
  description: 'Visual instruction tuning towards large language and vision models with GPT-4 level capabilities'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
  gpu: required
  parameters:
  - name: Port
    description: "Port to expose API on"
    type: int
    default: "5000"
  - name: CogImage
    description: "Model - https://replicate.com/google-research/maxim?input=docker"
    type: text
    default: "r8.im/google-research/maxim@sha256:494ca4d578293b4b93945115601b6a38190519da18467556ca223d219c3af9f9"
    readonly: true

# Helix

- id: helix-runner
  organization: Helix ML
  name: Runner
  categories:
  - OpenAI
  - ChatGPT
  - Text
  imageUrl: 'https://tryhelix.ai/assets/img/CDfWIfha3--900.webp'
  description: 'Attach a runner to your self-hosted Helix ML platform (https://tryhelix.ai)'
  specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/helix-runner.yaml
  gpu: required
  parameters:
  - name: ApiHost
    description: "API host of your Helix ML platform where controlplane is running"
    type: text
    default: ""
  - name: ModelDirectory
    description: "Directory to store model files"
    type: text
    default: "/data/helix"
  - name: ApiToken
    description: "Helix controlplane API token for the runners"
    type: text
    default: ""

# Nvidia 


# - id: llava-13b
#   name: Stable Diffusion XL
#   imageUrl: 'https://assets.nvidiagrid.net/ngc/logos/Triton-Inference-Server.png'
#   description: 'Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs. Triton supports an HTTP/REST and GRPC protocol that allows remote clients to request inferencing for any model being managed by the server.'
#   specUrl: https://raw.githubusercontent.com/synpse-hq/synpse/gallery/gallery/templates/replicate-cog.yaml
#   gpu: required
#   parameters:
#   - name: CogImage
#     description: "TODO"
#     type: text
#     default: "r8.im/yorickvp/llava-13b@sha256:01359160a4cff57c6b7d4dc625d0019d390c7c46f553714069f114b392f4a726"
#     readonly: true
